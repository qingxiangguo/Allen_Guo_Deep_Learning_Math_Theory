# _*_ coding=utf-8 _*_

"""
链式法则，也叫链式求导法则，是求多元函数导数的一种方法。
【在深度学习的神经网络中用来求每个样本损失函数，对于各个待优化的参数的偏导数，然后得到各自的梯度
以便后面使用梯度下降进行迭代】

它描述了如何用一个函数的导数来计算另一个函数的导数。
在微积分中链式法则是很重要的概念，用于计算复合函数的导数。

dy/dz = dy/du * du/dz

是链式法则的另一种形式。其实链式法则就是通过把复杂的问题分成多个简单问题来求解。
链式法则最重要的一个形式是

第一个公式：多元函数套一元函数

如果函数u=ϕ(t)以及v=ψ(t)都在t点可导， z=复合函数f(u,v)，在对应点
具有连续偏导数，那么复合函数z=f[ϕ(t),ψ(t)]在点t可导，且有：

dz/dt = ∂z/∂u * du/dt + ∂z/∂v * dv/dt  # ∂由于是两个变量，是偏导； d由于是一个变量，是普通导数

证明：要用到全微分公式，假设自变量t获得增量Δt，这时u=ϕ(t)以及v=ψ(t)对应增量为Δu, Δv
由于全微分公式：

全增量Δz = f(u0 + Δu, v0 + Δv) - f(u0, v0) = Δz = A*Δu + B*Δv + o（√(x²+y²)） 【高阶无穷小】

其中A代表z函数对u的偏导，B代表z函数对v的偏导

Δz可以表示为偏导数和增量的形式： Δz = ∂z/∂u * Δu + ∂z/∂v + Δv + 高阶无穷小（舍去）

两边除以Δt，得到：Δz/Δt = ∂z/∂u * Δu/Δt + ∂z/∂v * Δv/Δt

当Δt -> 0，两边求极限，lim Δt -> 0, Δz/Δt = ∂z/∂u * Δu/Δt + ∂z/∂v * Δv/Δt

就等于 dz/dt = ∂z/∂u * du/dt + ∂z/∂v * dv/dt

公式得证。

第二个公式：多元函数套多元函数

如果函数u=ϕ(x, y)以及v=ψ(x, y)都在(x, y)点具有对x和y的偏导数（多元复合一元中的说辞可导换成这个了）， z=复合函数f(u,v)，在对应点
(u, v)具有连续偏导数，那么复合函数z=f[ϕ(x, y),ψ(x, y)]在点(x, y)的两个偏导数都存在，且有：

∂z/∂x = ∂z/∂u * ∂u/∂x + ∂z/∂v + ∂v/∂x  【对x偏导数】

∂z/∂y = ∂z/∂u * ∂u/∂y + ∂z/∂v + ∂v/∂y   【对y偏导数】

注意，由于子函数也是多元函数，所以导数变成了偏导数
"""