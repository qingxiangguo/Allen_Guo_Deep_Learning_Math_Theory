# _*_ coding=utf-8 _*_

"""
还是以上述神经网络作为例子

一个简单的有两个隐藏层的神经网络示例，这个神经网络可以通过输入的，体重，身高，年龄三个数据，
输出性别，1代表男生，2代表女生，神经网络使用sigmoid激活函数，具体要求如下：

输入层: 包含3个神经元，输入信息为[x1, x2, x3]，分别对应体重，身高，年龄
第一个隐藏层:包含4个神经元（h1, h2, h3, h4），每个神经元都有3个输入权重(w1, w2, w3)和一个偏置项(b)
初始化: 随机初始化权重和偏置项
第二个隐藏层: 包含3个神经元 (h5, h6, h7)，每个神经元都有4个输入权重(w1, w2, w3, w4)和一个偏置项(b)
初始化: 随机初始化权重和偏置项
输出层：只有一个神经元，也使用sigmoid激活函数，以将输出转换为概率值。当输出值接近1时，则预测为男生，当输出值接近0时，则预测为女生。

现在有三个训练样本：person1, 120, 172, 28， 真实输出为1，代表男生;
person2, 100, 158, 22， 真实输出为0，代表女生;
person3, 92, 154, 64，真实输出为0，代表女生;

下面以批量梯度下降优化参数w81

批量梯度下降的例子如下：

首先，初始化所有参数。在上述例子中，有以下参数：w11, w12, w13, b1, w21, w22, w23, b2, w31, w32, w33, b3, w41, w42, w43, b4,
w51, w52, w53, w54, b5, w61, w62, w63, w64, b6, w71, w72, w73, w74, b7, w81, w82, w83, b8。

对于每一次迭代，对于三个样本（person1, person2, person3）分别进行正向传播，计算出每个样本的预测输出，然后计算出每个样本的损失函数值
（可以使用二分类交叉熵损失函数）。

然后，计算每一个样本的损失函数对每一个参数的偏导数。

用每个样本的损失函数对参数的偏导数的平均值来更新所有参数，比如：

w81 = w81 - learning_rate * (∂L1/∂w81 + ∂L2/∂w81 + ∂L3/∂w81) / 3

其中，learning_rate是学习率，∂L1/∂w81, ∂L2/∂w81, ∂L3/∂w81分别是三个样本对w81的偏导数。

重复这一过程，直到损失函数的值足够小，或者达到最大迭代次数。
这就是批量梯度下降的基本过程。
"""