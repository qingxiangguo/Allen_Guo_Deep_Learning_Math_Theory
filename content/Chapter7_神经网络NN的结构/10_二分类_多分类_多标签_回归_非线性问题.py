# _*_ coding=utf-8 _*_

"""
深度学习中，二分类，多分类，多标签，回归，非线性问题，输出层使用的激活函数不一样，得灵活处理。
下面是这些问题的实际具体例子。

二分类：通常使用Sigmoid激活函数
多分类：通常使用Softmax激活函数
多标签：通常使用Sigmoid激活函数
回归：通常使用恒等函数，即 f(x) = x，这是一个线性函数，不改变输入的形状。这意味着网络中的任何一个节点都不会对其输入进行任何非线性处理，
因此网络本质上是一个线性模型，无法处理复杂的非线性数据
非线性问题：通常使用ReLU、Tanh或者Sigmoid激活函数

对于二分类问题，通常使用sigmoid函数作为输出层的激活函数。Sigmoid函数可以将任意实数映射到0和1之间，
这正好符合二分类问题的需求，例如预测一个人是否有疾病。

对于多分类问题，通常使用softmax函数作为输出层的激活函数。
Softmax函数可以将任意实数向量映射到概率向量，例如预测图像的类别。

对于多标签问题，通常使用sigmoid函数作为输出层的激活函数，因为每个输出可以独立地被预测为0或1，而不需要相加为1
例如预测一部电影的类型（动作、爱情、喜剧等）。

对于回归问题，通常不使用激活函数，例如预测房价。

对于非线性问题，通常使用ReLU（rectified linear unit）函数作为隐藏层的激活函数，
因为ReLU函数可以快速地解决非线性问题，例如识别手写数字。
"""