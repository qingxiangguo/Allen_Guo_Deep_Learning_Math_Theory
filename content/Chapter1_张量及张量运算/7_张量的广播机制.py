# _*_ coding=utf-8 _*_
'''
如果一个Pytorch运算支持广播的话，那么就意味着传给这个运算的参数会被自动扩张成相同的size，在不复制数据的情况下就能进行运算，整个过程可以做到避免无用的复制，达到更高效的运算。
广播机制实际上是在运算过程中，去处理两个形状不同向量的一种手段。
pytorch中的广播机制和numpy中的广播机制一样, 因为都是数组的广播机制。

以数组A和数组B的相加为例, 其余数学运算同理
核心:如果相加的两个数组的shape不同, 就会触发广播机制：
      1）程序会自动执行操作使得A.shape==B.shape；
      2）对应位置进行相加运算，结果的shape是：A.shape和B.shape对应位置的最大值，比如：A.shape=(1,9,4),B.shape=(15,1,4),那么A+B的shape是(15,9,4)

'''

# 两个张量进行广播机制的条件一：两个张量都至少有一个元素
# 下面这个情况就不行，x是一维的，但是由于empty(0)，这唯一的一个维度里面，没有任何元素，所以无法广播
import torch

x = torch.empty(0,)  # tensor([])  一维张量
y = torch.empty(2, 2)
print(x)

# 如果修改成下面，就可以广播了

x = torch.empty(1,)  # tensor([])  一维张量
y = torch.empty(2, 2)

# 两个张量进行广播机制的条件二：
'''
按从右往左顺序看两个张量的每一个维度，x和y每个对应着的两个维度都需要能够匹配上。什么情况下算是匹配上了？满足下面的条件就可以：
      a.这两个维度的值大小相等
      b.某个维度 一个张量有，一个张量没有
      c.某个维度 一个张量有，一个张量也有但大小是1
如下举例：
'''
x = torch.empty(5, 3, 4, 1)
y = torch.empty(   3, 1, 1)
'''
两个张量第四维大小相等，都为1，满足上面条件a;第三个维度大小不相等，但第二个张量第三维大小为1，满足上面条件b;第二个维度大小相等都为3，
满足上面条件a;第一个维度第一个张量有，第二个张量没有，满足上面条件b，因此两个张量每个维度都符合上面广播条件，因此可以进行广播。
两个张量维度从右往左看，如果出现两个张量在某个维度位置上面，维度大小不相等，且两个维度大小没有一个是1，那么这两个张量一定不能进行广播。
'''

'''
当两个张量满足可广播条件后，具体怎么进行广播?
如上面代码所示：
a. 首先第一步，将上面条件b的类型变成条件c的类型，也即是把第二个张量在缺失维度的位置上新增一个维度，维度大小为1，新增的维度如下面所示。
'''
# 统一前:
x=torch.empty(5,3,4,1)
y=torch.empty( 3,1,1)
# 统一后：
x=torch.empty(5,3,4,1)
y=torch.empty(1,3,1,1)

'''
b. 第二步，x、y对应维度不等的位置，把size为1的维度会被广播得和对应维度一样大，
比如y中0维的1会变成5，y中2维的1会变成4，最后两个张量的维度大小变成一样，然后再进行张量运算，转变的维度如下所示。
'''

# 统一前:
x=torch.empty(5,3,4,1)
y=torch.empty(1,3,1,1)
# 统一后：
x=torch.empty(5,3,4,1)
y=torch.empty(5,3,4,1)




