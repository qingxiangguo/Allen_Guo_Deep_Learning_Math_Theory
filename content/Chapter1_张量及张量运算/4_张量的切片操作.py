# _*_ coding=utf-8 _*_
# 张量的计算操作多种多样，包括转置、索引、切片、数学运算、线性代数、随机抽样等等
import torch

tensor = torch.rand(3, 4)  # 创建一个3行4列的二维张量

# 张量的操作可以在GPU上运行（速度通常比在CPU上高）。如果你使用Colab，通过进入编辑>笔记本设置来分配一个GPU
# Colab = Colaboratory（即合作实验室），是谷歌提供的免费的GPU，CPU计算力高但核数量少，善于处理线性序列，
# 而GPU计算力低但核数量多，善于处理并行计算。在深度学习中使用GPU进行计算的速度要远快于CPU，因此有高算力的GPU是深度学习的重要保证。
# 因此Colab最大的优势在于我们可以“借用”谷歌免费提供的GPU来进行深度学习。

# 如果有cuda的话，把我们的张量移到GPU上
# 是Nvidia推出的只能用于自家GPU的并行计算框架。只有安装这个框架才能够进行复杂的并行计算。
# 主流的深度学习框架也都是基于CUDA进行GPU并行加速的，
# 几乎无一例外。还有一个叫做cudnn，是针对深度卷积神经网络的加速库。
if torch.cuda.is_available(): # 看是否安装了cuda
  tensor = tensor.to('cuda') #将张量加载到cuda平台上以实现GPU计算
  print(f"Device tensor is stored on: {tensor.device}")

# 索引和切片
tensor = torch.ones(4, 4) #创建一个4行4列的全1张量（二维）
print(tensor)

'''
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]])
'''
tensor[:,1] = 0  # 所有行，第二列变为0， 逗号前是第一个维度指令，:是从头：到尾：步长为1的缩写；逗号后是第二个维度指令
print(tensor)

'''
tensor([[1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.]])
'''