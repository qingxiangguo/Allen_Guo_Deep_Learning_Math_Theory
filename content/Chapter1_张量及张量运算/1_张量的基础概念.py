# _*_ coding=utf-8 _*_
'''
零维张量（tensor），又叫做标量，一维张量，又叫做向量，没有行列的概念，只有长度和大小，仅仅是一个箭头
二维张量，行和列，几行，几列，是矩阵；三维张量，有行，列，深度，也就是矩阵形成的数组(处理图像处理的时候，特别是彩色图像，含有RGB三个通道，那就必须要用三维张量才能进行表示)
将三维张量看作一个整体与个体，增加长度，为四维张量；四维张量增加行列信息后，又变成五维张量，
5维张量增加深度信息后，又变成6维张量，以此类推

一个二维张量，就是一个一维数组里面的所有元素（子单位）都是一个一维张量；

一个三维张量，就是一个一维数组里面的所有元素都是一个二维张量；

一个四维张量，就是一个一维数组里面的所有元素都是一个三维张量；

张量在PyTorch中支持GPU运算和自动求梯度等功能

在pytroch中，维度数就看中括号的数量，零维张量如下：

tensor(1)  # 注意tensor([1])是一维张量而不是零维张量

一维张量如下：

长度为3的一维张量a: tensor([0.8206, 0.6208, 0.2549])

二维张量表示如下，是一个4X4的矩阵：

tensor([[1., 1., 1., 1.,]
        [1., 1., 1., 1.,]
        [1., 1., 1., 1.,]
        [1., 1., 1., 1.,]])

2行3列的二维张量b:

tensor([[0.9667, 0.8103, 0.6089],
        [0.5163, 0.8044, 0.7744]])

两个两行三列的矩阵，三维张量c:

tensor([[[0.8929, 0.0102, 0.2182],
         [0.4855, 0.0377, 0.8328]],

        [[0.4653, 0.6590, 0.4474],
         [0.6367, 0.2073, 0.6972]]])

实际上是等价于下面，

a1 = np.array([[0.8929, 0.0102, 0.2182], [0.4855, 0.0377, 0.8328]])
a2 = np.array([[0.4653, 0.6590, 0.4474], [0.6367, 0.2073, 0.6972]])
t3 = torch.tensor([a1,a2])
t3.shape   # 结果为torch.Size([2,2,3])

标量
标量就是一个数字。标量也称为0维数组。

比如5套房子中的“5”就是标量；

向量
向量是一组标量组成的列表。向量也称为1维数组。

比如房子的价格是受多种因素（是否为学区房、附近有无地铁、房子面积、房间数量、楼层等）来影响，那么我们将这多种因素来表示为房子的特征，这一组特征值就可以用向量表示。

矩阵
矩阵是由一组向量组成的集合。矩阵也称为2维数组。

在刚才的例子中，一套房子的特征可以用一个向量来表示。那么我们要建m套房子的数据集，那么就是m个向量的组合，也即是得到一个m行n列的矩阵。（n为一套房子的向量的长度）。

张量
张量是矩阵的推广，可以用来描述N维数据。其实在计算机领域内，大家叫法都不那么严格，一个矩阵，你可以叫它矩阵，也可以叫它二阶张量，也可以叫它二维数组。大家都能理解是什么意思。

张量在图像领域用的是很普遍的。比如一张彩色图像，有宽度和高度，同时又有R,G,B三个通道。所以一张彩色图像就是三阶张量。

再高一阶的四阶张量，可以理解为一个批次的彩色图像。因为在做图像识别过程中，我们训练和推理过程中可以一次推理N张图像，这个N称为批次。即是 批次 * 通道 * 宽度 *高度 的四阶张量。
'''

