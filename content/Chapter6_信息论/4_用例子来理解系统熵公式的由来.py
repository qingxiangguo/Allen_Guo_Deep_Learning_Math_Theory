# _*_ coding=utf-8 _*_

"""
假设有两场球赛，第一场，阿根廷对比利时，每个赢球的概率都是1/2，第二场是中国对法国，中国赢球概率是1%，法国是99%

显然，是第一场比赛，从不确定到确定的难度更大，因为两边都是五五开，难分胜负，所以第一个比赛系统的熵也应该更大

具体来看，第一场比赛，阿根廷信息量 = -log2(1/2) = 1; 比利时信息量 = -log2(1/2) = 1

对于整个比赛系统的信息量怎么算呢？是直接把他们加起来，一加一等于2吗？我们先放一放

第二场，法国赢球信息量很低： -log2(0.99) = 0.0145, 比利时赢球信息量 = 6.6439

如果只是粗暴的相加，0.0145 + 6.6439 肯定大于 2，难道第二场比较的熵更大吗？这显然不合适

所以每个事件还要乘以自己的概率，也就是法国赢球这个事件，对整个系统贡献了多少信息量

所以第一场比较的熵 = 1*1/2 + 1*1/2 = 1

第二场的熵 = 0.0145 * 0.99 + 6.6439 * 0.01 = 0.080794

第一场 > 第二场，这样才合适

对于一个系统，整个系统的熵，就是把里面所有可能发生的事件的每个信息量，求出来
然后和这个事件，发生的概率相乘，最后把所有的事件都加起来，就是系统熵

而把某个值和自己发生概率相乘，最后再全部相加的操作，其实就是取期望

所以【假设有一个概率系统P，系统熵等于这个系统信息量的期望】

"""