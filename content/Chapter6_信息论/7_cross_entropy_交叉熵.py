# _*_ coding=utf-8 _*_

"""
熵的公式 = -∑ p(x)* log2(p(x))，也就是系统中所有事件信息量的期望

重要的事情再说一遍：“熵是服从某一特定概率分布事件的理论最小平均编码长度”，只要我们知道了任何事件的概率分布，我们就可以计算它的熵，熵就是确定的

那如果我们不知道事件的概率分布，又想计算熵，该怎么做呢？那我们来对熵做一个估计吧，熵的估计的过程自然而然的引出了交叉熵。

假如我们现在需要预报东京天气，在真实天气发生之前，我们不可能知道天气的概率分布；但为了下文的讨论，我们需要假设：
对东京天气做一段时间的观测后，可以得到真实的概率分布P（真实值）。

在观测之前，我们只有预估的概率分布Q，使用估计得到的概率分布Q（预测值），可以计算估计的熵：

熵 = -∑ Q(x)* log2(Q(x))，这里期望概率和每个事件的最小编码长度，都是用Q来估计的

如果Q是真实的概率分布，根据上述公式，我们已经得到了编码东京天气信息的最小平均长度；然而估计的概率分布为我们的公式引入了两部分的不确定性：

计算期望的概率分布是Q，与真实的概率分布P不同。
计算最小编码长度的概率是 -logQ(x)，与真实的最小编码长度 -logP(x) 不同。

因为估计的概率分布Q影响了上述两个部分(期望和编码长度)，所以得到的结果很可能错得离谱，也因此该结果和真实熵的对比无意义。和香农的目标一样，
我们希望编码长度尽可能的短，所以我们需要对比我们的编码长度-∑ Q(x)* log2(Q(x))和理论上的最小编码长度(熵，也就是-∑ p(x)* log2(p(x)))。

假设经过观测后，我们得到了真实概率分布P，在天气预报时，就可以使用P计算平均编码长度，实际编码长度基于Q计算，这个计算结果就是P和Q的交叉熵。
这样，实际编码长度和理论最小编码长度就有了对比的意义。

交叉熵公式： H(P, Q) = -∑ P(x) * log(Q(x))  # 使用真实分布P的概率，使用预测分布Q的信息量

交叉熵 >= 熵

交叉熵使用H(P,Q)表示，意味着使用P计算期望，使用Q计算编码长度；所以H(P,Q)并不一定等于H(Q,P)，除了在P=Q的情况下，H(P,Q) = H(Q,P) = H(P)。

有一点很微妙但很重要：对于期望，我们使用真实概率分布P来计算；对于编码长度，我们使用假设的概率分布Q来计算，因为它是预估用于编码信息的。
因为熵是理论上的平均最小编码长度，
所以交叉熵只可能大于等于熵。换句话说，如果我们的估计是完美的，即Q=P，那么有H(P,Q) = H(P)，否则，H(P,Q) > H(P)。

"""