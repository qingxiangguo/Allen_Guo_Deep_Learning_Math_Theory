# _*_ coding=utf-8 _*_

"""
在上面举的这个神经网络例子中，可以观察到链式法则的多途径性，也就是损失函数对同一个参数的表示，
可以有多种不同的链式法则，比如损失函数 L 对 w21 的偏导数

∂L/∂w21 = ∂L/∂h8 * ∂h8/∂h5 * ∂h5/∂h2 * ∂h2/∂w21

也可以表示为

∂L/∂w21 = ∂L/∂h8 * ∂h8/∂h6 * ∂h6/∂h2 * ∂h2/∂w21

多途径性在数学上叫做多重链式法则，它指的是一个函数的梯度（即导数）可以通过多种不同的途径来表示。
在神经网络的学习中，多重链式法则指的是，一个参数对最终的损失函数的影响可以通过多种不同的路径被表示出来。
这种方法的好处是，可以更好的利用已知的梯度信息，并且可以进行优化，从而加速模型的学习过程。

比如在反向传播过程中，需要对每一个参数计算对应的梯度。如果有多种不同的路径可以表示一个参数对最终损失函数的影响，
那么可以选择其中一个计算梯度最快的路径，加速计算梯度的过程。
"""