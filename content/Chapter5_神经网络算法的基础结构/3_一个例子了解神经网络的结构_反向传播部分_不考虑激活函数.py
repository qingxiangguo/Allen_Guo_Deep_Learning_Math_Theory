# _*_ coding=utf-8 _*_

"""
还是以上面那个神经网络作为例子

一个简单的有两个隐藏层的神经网络示例，这个神经网络可以通过输入的，体重，身高，年龄三个数据，
输出性别，1代表男生，2代表女生，神经网络使用sigmoid激活函数，具体要求如下：

输入层: 包含3个神经元，输入信息为[x1, x2, x3]，分别对应体重，身高，年龄
第一个隐藏层:包含4个神经元（h1, h2, h3, h4），每个神经元都有3个输入权重(w1, w2, w3)和一个偏置项(b)
初始化: 随机初始化权重和偏置项
第二个隐藏层: 包含3个神经元 (h5, h6, h7)，每个神经元都有4个输入权重(w1, w2, w3, w4)和一个偏置项(b)
初始化: 随机初始化权重和偏置项
输出层：只有一个神经元，也使用sigmoid激活函数，以将输出转换为概率值。当输出值接近1时，则预测为男生，当输出值接近0时，则预测为女生。

现在有三个训练样本：person1, 120, 172, 28， 真实输出为1，代表男生;
person2, 100, 158, 22， 真实输出为0，代表女生;
person3, 92, 154, 64，真实输出为0，代表女生;

【第一次正向传播】以第一个样本为例子，现在随机初始化，

输入层，没参数

第一个隐藏层: h1, h2, h3, h4是四个神经元
h1的参数，w11 = 0.1, w12 = 0.2, w13 = 0.3, b1 = 0.4
h2的参数，w21 = 0.5, w22 = 0.6, w23 = 0.7, b2 = 0.8
h3的参数，w31 = 0.9, w32 = 1.0, w33 = 1.1, b3 = 1.2
h4的参数，w41 = 1.3, w42 = 1.4, w43 = 1.5, b4 = 1.6

第二个隐藏层: h5, h6, h7是三个神经元
h5的参数，w51 = 1.7, w52 = 1.8, w53 = 1.9, w54 = 2.0, b5 = 2.1
h6的参数，w61 = 2.2, w62 = 2.3, w63 = 2.4, w64 = 2.5, b6 = 2.6
h7的参数，w71 = 2.7, w72 = 2.8, w73 = 2.9, w74 = 3.0, b7 = 3.1

输出层有一个神经元(h8)参数的权重是3个，分别对应第二个隐藏层的3个神经元

h8的参数，w81 = 3.2, w82 = 3.3, w83 = 3.4, b8 = 3.5

【下面正式开始第一次正向传播】

输入层: 体重120, 身高172, 年龄28
第一个隐藏层: 计算每个神经元的输入信号, 使用输入值乘以权重，求和, 然后加上偏置项,
并使用sigmoid激活函数计算输出值

第一个隐藏层:

h1 (隐藏层中的第一个神经元): 输入信号 = x1w11 + x2w12 + x3w13 + b1 = 120*0.1 + 172*0.2 + 28*0.3 + 0.4 = 55.2,
 输出值 = sigmoid(55.2) = 1
h2: 输入信号 = x1w21 + x2w22 + x3w23 + b2 = 120*0.5 + 172*0.6 + 28*0.7 + 0.8 = 183.6,
 输出值 = sigmoid(183.6) = 1
h3: 输入信号 = x1w31 + x2w32 + x3w33 + b3 = 120*0.9 + 172*1.0 + 28*1.1 + 1.2 = 312,
 输出值 = sigmoid(312) = 1
h4: 输入信号 = x1w41 + x2w42 + x3w43 + b4 = 120*1.3 + 172*1.4 + 28*1.5 + 1.6 = 440.4,
 输出值 = sigmoid(440.4) = 1

第二个隐藏层:

h5: 输入信号 = h1w51 + h2w52 + h3w53 + h4w54 + b5 = 1*1.7 + 1*1.8 + 1*1.9 + 1*2.0 + 2.1 = 9.5,
输出值 = sigmoid(9.5) = 0.9999
h6: 输入信号 = h1w61 + h2w62 + h3w63 + h4w64 + b6 = 1*2.2 + 1*2.3 + 1*2.4 + 1*2.5 + 2.6 = 12,
输出值 = sigmoid(12) = 0.9999
h7: 输入信号 = h1w71 + h2w72 + h3w73 + h4w74 + b7 = 1*2.7 + 1*2.8 + 1*2.9 + 1*3.0 + 3.1 = 14.5,
输出值 = sigmoid(14.5) = 0.9999

输出层:
输入信号h8 = h5*w81 + h6*w82 + h7*w83 + b8 = 0.9999*3.2 + 0.9999*3.3 + 0.999*3.4 + 3.5 = 13.395
输出值 = sigmoid(13.39) = 0.9999  # 这里输出层用了sigmoid激活函数，实际情况中不是必须的

结论，预测为男生，输出值为0.9999

请注意，这只是一次计算过程，并不代表模型训练成功。

【下面正式开始第一次反向传播】

在计算输出层的输出之后，计算输出层与真实输出之间的误差。然后，使用反向传播算法通过计算
每个权重的导数，以减少误差。最后，使用梯度下降法更新权重和偏置项，
使误差越来越小。这个过程可以重复多次，直到网络在训练数据上的误差达到了接受的水平。

在反向传播的过程中，首先需要计算损失函数，用预测值和真实值之间的差来评估模型的好坏。
我们使用的损失函数，L = (y真实值-y预测值)^2

接下来，我们求每一个参数的梯度, 参数太多了，一个个列出来也比较麻烦，我们仅列出损失函数对w51, w81, w11的梯度的计算过程
第一隐藏层是h1, h2, h3, h4，第二隐藏层是 , h5, h6, h7， 输出层是h8，
同时，我们也以h8, h5分别指代神经元的输出结果（暂不考虑激活函数求导）

【损失函数 L 对 w11 的偏导数】

∂L/∂w11 = ∂L/∂h8 * ∂h8/∂h5 * ∂h5/∂h1 * ∂h1/∂w11

其中，

h1 = w11 * x1 + w12 * x2 + w13 * x3 + b1

h5 = w51 * h1 + w52 * h2 + w53 * h3 + w54 * h4 + b5

h8 = w81 * h5 + w82 * h6 + w83 * h7 + b8

L = (y_true - h8)^2

首先求出 L 对 h8 的偏导数：

∂L/∂h8 = -2 * (y_true - h8)

再求出 h8 对 h5 的偏导数：

∂h8/∂h5 = w81

再求出 h5 对 h1 的偏导数：

∂h5/∂h1 = w51

最后求出 h1 对 w11 的偏导数：

∂h1/∂w11 = x1

综上所述：

∂L/∂w11 = ∂L/∂h8 * ∂h8/∂h5 * ∂h5/∂h1 * ∂h1/∂w11 = -2 * (y_true - h8) * w81 * w51 * x1

最终结果需要根据具体的数值来计算。

【损失函数 L 对 w51 的偏导数】，其中h8是最终输出的预测值，根据链式法则：
∂L/∂w51 = ∂L/∂h8 * ∂h8/∂h5 * ∂h5/∂w51
该公式表示：首先需要求出 L 对 h8 的偏导数，再求出 h8 对 h5 的偏导数，最后求出 h5 对 w51 的偏导数。
因此，我们可以利用链式法则，逐层推导得到最终的结果。

其中，
L = (y真实值-h8)^2

h8 = w81*h5 + w82*h6 + w83*h7 + b8

h5 = w51*h1 + w52*h2 + w53*h3 + w54*h4 + b5

所以，∂L/∂w51 = ∂L/∂h8 * ∂h8/∂h5 * ∂h5/∂w51 = -2*(y真实值 - h8) * w81 * h1
又因为h1 = 55.2; w81 =3.2; -2*(y真实值 - h8) = -2*(1 - 13.395)
所以，∂L/∂w51 = ∂L/∂h8 * ∂h8/∂h5 * ∂h5/∂w51 = 4378.9056  # 注意这里没考虑激活函数，所以数字这么大

【损失函数 L 对 w81 的偏导数】

首先，L = (y真实值 - h8)^2； h8 = w81 * h5 + w82 * h6 + w83 * h7 + b8

∂L/∂w81 = ∂L/∂h8 * ∂h8/∂w81 = -2 * (y真实值 - h8) * h5

因此，∂L/∂w81 = -2 * (y真实值 - h8) * h5。 注意：同样需要计算出 y 真实值与 h8 的差值以及 h5 的值，才能得到最终的结果。
"""